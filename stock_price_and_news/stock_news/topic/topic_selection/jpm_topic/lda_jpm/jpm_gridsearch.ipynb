{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_soup = BeautifulSoup(open(r\"C:\\Users\\User\\Desktop\\thesis_17_3_2022\\stock_price_and_news\\stock_news\\dataset\\jpm_final\\jpm_2012_jan.html\", encoding=\"utf8\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_timestamp = []\n",
    "for e in jpm_soup.find_all(\"span\", {\"class\": \"article__timestamp\"}):\n",
    "    jpm_timestamp.append(e.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_file = []\n",
    "for jpm_text in jpm_soup.find_all(\"h3\"):\n",
    "    jpm_file.append(jpm_text.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n                            \\n                            DCM Advisors, LLC Buys Apple Inc, Microsoft Corp, Alphabet Inc, Sells MetLife Inc, Qorvo Inc, ...\\n                        \\n',\n",
       " '\\n\\n                            \\n                            Down 38% From Its High, Is This Fintech a Buy?\\n                        \\n',\n",
       " '\\n\\n                            \\n                            1 Key Metric Shows How Wells Fargo Can Recover\\n                        \\n',\n",
       " \"\\n\\n                            \\n                            Here's Another Reason Why Shopify Is an Unstoppable E-Commerce Stock to Buy in 2022\\n                        \\n\",\n",
       " '\\n\\n                            \\n                            ING Groep NV Buys Amazon.com Inc, Micron Technology Inc, JPMorgan Chase, Sells Enterprise ...\\n                        \\n',\n",
       " '\\n\\n                            \\n                            Goodbye Accommodating Fed, JPMorgan Could Rise Sharply\\n                        \\n',\n",
       " '\\n\\n                            \\n                            Carl P. Sherr & Co., LLC Buys Apple Inc, Safety Insurance Group Inc, American Express Co, ...\\n                        \\n',\n",
       " 'MarketWatch',\n",
       " 'Company',\n",
       " 'Dow Jones Network']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpm_file[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_clean1 = []\n",
    "for jpm_text1 in jpm_file:\n",
    "    jpm_clean1.append(jpm_text1.replace(\"\\n\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_remove = []\n",
    "for e in jpm_clean1:\n",
    "    if e not in (\"Barron'sStocks Wobble With Fed Minutes Ahead\",\n",
    " '',\n",
    " \"Barron'sUpstart Stock Surges on Strong Revenue Forecast and Buyback Plans\",\n",
    " 'Personal loans and taxes: Don’t let this ‘unpleasant surprise’ happen to you if you take out a personal loan',\n",
    " 'Midcareer millennials now have negotiating power—how to get the job you want, on the terms you want',\n",
    " 'The 2022 Ford Mustang Mach-E—practical and high tech, with performance that lives up to its name',\n",
    " 'Trying to build a business in midlife? Here are 7 tips from 2 marketing masters',\n",
    " \"Barron'sNvidia's Earnings Are Today. Gaming and Data Center Are the Money Makers.\",\n",
    " \"Barron'sThe largest Fancy Vivid Blue Diamond to Hit Auction for $48 Million\",\n",
    " 'UpdatedEricsson shares slump as telecommunications firm says it may have made payments to Islamic State',\n",
    " 'Ericsson shares slump as telecommunications firm says it may have made payments to Islamic State',\n",
    " 'With a tiger and Jamie Dimon, JPMorgan enters the metaverse',\n",
    " 'Ericsson discloses ‘serious breach of compliance rules’ in Iraq dealings',\n",
    " 'The end of the pandemic may be in sight, says Moderna CEO',\n",
    " \"Barron'sPublicly Traded Companies Are Vanishing. Does Private Equity Have an Edge?\",\n",
    " \"Barron'sWynn Stock Falls After Quarterly Loss Wider Than Estimates\",\n",
    " \"Barron'sThe ARK Innovation Selloff Looks Like the Dot-Com Bust. History Says It Gets Worse.\",\n",
    " \"Barron'sWynn Stock Falls After Quarterly Loss Wider Than Estimates\",\n",
    " \"Barron'sCisco Earnings Are Coming. Watch Hardware Production. \",\n",
    " 'No Recent Tickers',\n",
    " 'Overview'):\n",
    "        jpm_remove.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_space = []\n",
    "for e in jpm_remove:\n",
    "    jpm_space.append(e.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_fullstop = []\n",
    "for e in jpm_space:\n",
    "    jpm_fullstop.append(e.replace(\".\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_q = []\n",
    "for e in jpm_fullstop:\n",
    "    jpm_q.append(e.replace(\"?\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_colon = []\n",
    "for e in jpm_q:\n",
    "    jpm_colon.append(e.replace(\":\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_comma = []\n",
    "for e in jpm_colon:\n",
    "    jpm_comma.append(e.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_percent = []\n",
    "for e in jpm_comma:\n",
    "    jpm_percent.append(e.replace(\"%\",\"percent\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_lower = []\n",
    "for i in range(len(jpm_percent)):\n",
    "    jpm_lower.append(jpm_percent[i].lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_pain = []\n",
    "for e in jpm_lower:\n",
    "    if e not in ( 'marketwatch',\n",
    " 'company',\n",
    " 'dow jones network'):\n",
    "        jpm_pain.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['goelzer investment management inc buys exxon mobil corp jpmorgan chase fidelity national ',\n",
       " 'why mastercard expects earnings to double over the next four years',\n",
       " 'monday afternoon top analyst upgrades and downgrades duke energy goodyear jpmorgan juniper networks and more',\n",
       " 'dcm advisors llc buys apple inc microsoft corp alphabet inc sells metlife inc qorvo inc ',\n",
       " 'down 38percent from its high is this fintech a buy',\n",
       " '1 key metric shows how wells fargo can recover',\n",
       " \"here's another reason why shopify is an unstoppable e-commerce stock to buy in 2022\",\n",
       " 'ing groep nv buys amazoncom inc micron technology inc jpmorgan chase sells enterprise ',\n",
       " 'goodbye accommodating fed jpmorgan could rise sharply',\n",
       " 'carl p sherr & co llc buys apple inc safety insurance group inc american express co ']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpm_pain[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_timestamp = []\n",
    "for e in jpm_soup.find_all(\"span\", {\"class\": \"article__timestamp\"}):\n",
    "    jpm_timestamp.append(e.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_et = []\n",
    "for e in jpm_timestamp:\n",
    "    jpm_et.append(e.replace(\"ET\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_at1 = []\n",
    "for e in jpm_et:\n",
    "    jpm_at1.append(e.replace(\"at\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_pm1 = []\n",
    "for e in jpm_at1:\n",
    "    jpm_pm1.append(e.replace(\"p.m.\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_am1 = []\n",
    "for e in jpm_pm1:\n",
    "    jpm_am1.append(e.replace(\"a.m.\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_commas = []\n",
    "for e in jpm_am1:\n",
    "    jpm_commas.append(e.replace(\",\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_fullstops = []\n",
    "for e in jpm_commas:\n",
    "    jpm_fullstops.append(e.replace(\".\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_timestamp_final = jpm_fullstops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_date = [datetime.strptime(x,'%b %d %Y  %I:%M ') for x in jpm_timestamp_final]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(stop_words='english', max_features=500000000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jpm_data = pd.DataFrame(\n",
    "    {'Date': jpm_date,\n",
    "     'text_headlines': jpm_pain\n",
    "     \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text_headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-15 09:10:00</td>\n",
       "      <td>the beginning of the ‘new normal’ more compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-15 05:02:00</td>\n",
       "      <td>jpmorgan chase &amp; co stock rises tuesday still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-15 03:10:00</td>\n",
       "      <td>city of london’s lord mayor arrives in the us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-14 05:02:00</td>\n",
       "      <td>jpmorgan chase &amp; co stock outperforms competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-14 01:26:00</td>\n",
       "      <td>goodyear stock plunged friday this analyst say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date                                     text_headlines\n",
       "0 2022-02-15 09:10:00  the beginning of the ‘new normal’ more compani...\n",
       "1 2022-02-15 05:02:00  jpmorgan chase & co stock rises tuesday still ...\n",
       "2 2022-02-15 03:10:00  city of london’s lord mayor arrives in the us ...\n",
       "3 2022-02-14 05:02:00  jpmorgan chase & co stock outperforms competit...\n",
       "4 2022-02-14 01:26:00  goodyear stock plunged friday this analyst say..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpm_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jpm_data.to_csv('jpm_topic_selection.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "jpm_news_matrix = tf_vectorizer.fit_transform(jpm_data['text_headlines'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the beginning of the ‘new normal’ more compani...\n",
       "1    jpmorgan chase & co stock rises tuesday still ...\n",
       "2    city of london’s lord mayor arrives in the us ...\n",
       "3    jpmorgan chase & co stock outperforms competit...\n",
       "4    goodyear stock plunged friday this analyst say...\n",
       "Name: news_text_processed, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "jpm_data['news_text_processed'] = jpm_data['text_headlines'].map(lambda x: re.sub(\"[,\\.!?']\", \"\", x))\n",
    "# Convert the titles to lowercase\n",
    "jpm_data['news_text_processed'] = jpm_data['text_headlines'].map(lambda x: x.lower())\n",
    "# Print out the first rows of papers\n",
    "jpm_data['news_text_processed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>text_headlines</th>\n",
       "      <th>news_text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-15 09:10:00</td>\n",
       "      <td>the beginning of the ‘new normal’ more compani...</td>\n",
       "      <td>the beginning of the ‘new normal’ more compani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-15 05:02:00</td>\n",
       "      <td>jpmorgan chase &amp; co stock rises tuesday still ...</td>\n",
       "      <td>jpmorgan chase &amp; co stock rises tuesday still ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-15 03:10:00</td>\n",
       "      <td>city of london’s lord mayor arrives in the us ...</td>\n",
       "      <td>city of london’s lord mayor arrives in the us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-14 05:02:00</td>\n",
       "      <td>jpmorgan chase &amp; co stock outperforms competit...</td>\n",
       "      <td>jpmorgan chase &amp; co stock outperforms competit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-14 01:26:00</td>\n",
       "      <td>goodyear stock plunged friday this analyst say...</td>\n",
       "      <td>goodyear stock plunged friday this analyst say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Date                                     text_headlines  \\\n",
       "0 2022-02-15 09:10:00  the beginning of the ‘new normal’ more compani...   \n",
       "1 2022-02-15 05:02:00  jpmorgan chase & co stock rises tuesday still ...   \n",
       "2 2022-02-15 03:10:00  city of london’s lord mayor arrives in the us ...   \n",
       "3 2022-02-14 05:02:00  jpmorgan chase & co stock outperforms competit...   \n",
       "4 2022-02-14 01:26:00  goodyear stock plunged friday this analyst say...   \n",
       "\n",
       "                                 news_text_processed  \n",
       "0  the beginning of the ‘new normal’ more compani...  \n",
       "1  jpmorgan chase & co stock rises tuesday still ...  \n",
       "2  city of london’s lord mayor arrives in the us ...  \n",
       "3  jpmorgan chase & co stock outperforms competit...  \n",
       "4  goodyear stock plunged friday this analyst say...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jpm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'beginning', 'of', 'the', 'new', 'normal', 'more', 'companies', 'drop', 'covid', 'restrictions', 'as', 'omicron', 'wanes']\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "data = jpm_data.news_text_processed.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "print(data_words[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# NLTK Stop words\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['begin', 'new', 'normal', 'company', 'drop', 'restriction', 'omicron', 'wane']]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]]\n"
     ]
    }
   ],
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=2, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=10,\n",
    "                                       passes=1,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.045*\"stock\" + 0.034*\"market\" + 0.019*\"financial\" + 0.019*\"rise\" + '\n",
      "  '0.008*\"bank\" + 0.007*\"outperform\" + 0.007*\"say\" + 0.007*\"sector\" + '\n",
      "  '0.007*\"still\" + 0.006*\"underperform\"'),\n",
      " (1,\n",
      "  '0.046*\"stock\" + 0.037*\"bank\" + 0.025*\"financial\" + 0.022*\"percent\" + '\n",
      "  '0.015*\"earning\" + 0.014*\"share\" + 0.013*\"lead\" + 0.013*\"buy\" + 0.013*\"gain\" '\n",
      "  '+ 0.012*\"big\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  -7.372825308779779\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = gensim.models.CoherenceModel(model=lda_model, texts=data_lemmatized,corpus=corpus, dictionary=id2word, coherence='u_mass')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=10,\n",
    "                                           passes=1,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='u_mass')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [1:54:52<00:00, 12.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import CoherenceModel\n",
    "import numpy as np\n",
    "import tqdm\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 6\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [# gensim.utils.ClippedCorpus(corpus, num_of_docs*0.25), \n",
    "               # gensim.utils.ClippedCorpus(corpus, num_of_docs*0.5), \n",
    "               gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=540)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

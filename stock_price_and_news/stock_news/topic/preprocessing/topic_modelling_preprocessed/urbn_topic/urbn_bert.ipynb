{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_merge = pd.read_csv(r'C:\\Users\\User\\Desktop\\thesis_17_3_2022\\stock_price_and_news\\topic\\topic_selection\\urbn_topic\\stock_urbn.csv')\n",
    "urbn_sales_merge = pd.read_csv(r'C:\\Users\\User\\Desktop\\thesis_17_3_2022\\stock_price_and_news\\topic\\topic_selection\\urbn_topic\\sales_urbn.csv')\n",
    "urbn_management_merge = pd.read_csv(r'C:\\Users\\User\\Desktop\\thesis_17_3_2022\\stock_price_and_news\\topic\\topic_selection\\urbn_topic\\management_urbn.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_merge1 = urbn_stock_merge['text_headlines']\n",
    "urbn_sales_merge1 = urbn_sales_merge['text_headlines']\n",
    "urbn_management_merge1 = urbn_management_merge['text_headlines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_merge2 = urbn_stock_merge1.to_list()\n",
    "urbn_sales_merge2 = urbn_sales_merge1.to_list()\n",
    "urbn_management_merge2 = urbn_management_merge1.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer,AutoModelForSequenceClassification\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased',num_labels = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x, axis=1)[:, None])\n",
    "    return e_x / np.sum(e_x, axis=1)[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05212656  0.052037   -0.01846632  0.05390933  0.03768569  0.06710097\n",
      "  0.00879949  0.03855762 -0.03870282  0.03423059]\n"
     ]
    }
   ],
   "source": [
    "label_dict = {0: 'positive', 1: 'negative', 2: 'neutral'}\n",
    "urbn_out_stock = []\n",
    "urbn_score_stock = []\n",
    "for i in range(0, len(urbn_stock_merge2), 10):\n",
    "    tokenized_urbn_stock = tokenizer(urbn_stock_merge2[i:i+10], truncation = True, padding = True, return_tensors = \"pt\")\n",
    "    urbn_output_stock = model(tokenized_urbn_stock['input_ids'])\n",
    "    soft_logits_stock = softmax(np.array(urbn_output_stock.logits.detach().cpu()))\n",
    "    sentiment_score_stock = soft_logits_stock[:,0]-soft_logits_stock[:,1]\n",
    "    urbn_pred_stock = np.squeeze(np.argmax(soft_logits_stock, axis = 1))\n",
    "    urbn_out_stock.extend(urbn_pred_stock)\n",
    "    urbn_score_stock.extend(sentiment_score_stock)\n",
    "#print(jpm_out) \n",
    "print(sentiment_score_stock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "590\n"
     ]
    }
   ],
   "source": [
    "print(len(urbn_out_stock))\n",
    "urbn_class_stock = [label_dict[pred] for pred in urbn_out_stock]\n",
    "print(len(urbn_class_stock))\n",
    "#print(tsla_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.04143271 -0.06868663 -0.06087306]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urbn_out_sales = []\n",
    "urbn_score_sales = []\n",
    "for i in range(0, len(urbn_sales_merge2), 10):\n",
    "    tokenized_urbn_sales = tokenizer(urbn_sales_merge2[i:i+10], truncation = True, padding = True, return_tensors = \"pt\")\n",
    "    urbn_output_sales = model(tokenized_urbn_sales['input_ids'])\n",
    "    soft_logits_sales = softmax(np.array(urbn_output_sales.logits.detach().cpu()))\n",
    "    sentiment_score_sales = soft_logits_sales[:,0]-soft_logits_sales[:,1]\n",
    "    urbn_pred_sales = np.squeeze(np.argmax(soft_logits_sales, axis = 1))\n",
    "    urbn_out_sales.extend(urbn_pred_sales)\n",
    "    urbn_score_sales.extend(sentiment_score_sales)\n",
    "#print(jpm_out) \n",
    "print(sentiment_score_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n",
      "433\n"
     ]
    }
   ],
   "source": [
    "print(len(urbn_out_sales))\n",
    "urbn_class_sales = [label_dict[pred] for pred in urbn_out_sales]\n",
    "print(len(urbn_class_sales))\n",
    "#print(tsla_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06228721 -0.06158289]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "urbn_out_management = []\n",
    "urbn_score_management = []\n",
    "for i in range(0, len(urbn_management_merge2), 10):\n",
    "    tokenized_urbn_management = tokenizer(urbn_management_merge2[i:i+10], truncation = True, padding = True, return_tensors = \"pt\")\n",
    "    urbn_output_management = model(tokenized_urbn_management['input_ids'])\n",
    "    soft_logits_management = softmax(np.array(urbn_output_management.logits.detach().cpu()))\n",
    "    sentiment_score_management = soft_logits_management[:,0]-soft_logits_management[:,1]\n",
    "    urbn_pred_management = np.squeeze(np.argmax(soft_logits_management, axis = 1))\n",
    "    urbn_out_management.extend(urbn_pred_management)\n",
    "    urbn_score_management.extend(sentiment_score_management)\n",
    "#print(jpm_out) \n",
    "print(sentiment_score_management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n",
      "312\n"
     ]
    }
   ],
   "source": [
    "print(len(urbn_out_management))\n",
    "urbn_class_management = [label_dict[pred] for pred in urbn_out_management]\n",
    "print(len(urbn_class_management))\n",
    "#print(tsla_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "urbn_stock_price  = yf.download('urbn', start='2003-10-20', end='2022-04-03', time_interval = 'daily')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_price = urbn_stock_price.drop(['Open', 'High','Low','Volume', 'Adj Close'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "urbn_scaler_price = scaler.fit_transform(urbn_stock_price.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_date = urbn_stock_merge['Date']\n",
    "urbn_management_date = urbn_management_merge['Date']\n",
    "urbn_sales_date = urbn_sales_merge['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_score_stock = pd.DataFrame (urbn_score_stock, columns = ['sentiment_score'])\n",
    "urbn_score_management = pd.DataFrame (urbn_score_management, columns = ['sentiment_score'])\n",
    "urbn_score_sales = pd.DataFrame (urbn_score_sales, columns = ['sentiment_score'])\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "urbn_stock_scaler = scaler.fit_transform(urbn_score_stock.values.reshape(-1,1))\n",
    "urbn_management_scaler = scaler.fit_transform(urbn_score_management.values.reshape(-1,1))\n",
    "urbn_sales_scaler = scaler.fit_transform(urbn_score_sales.values.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_scaler = pd.DataFrame (urbn_stock_scaler, columns = ['sentiment_score'])\n",
    "urbn_management_scaler = pd.DataFrame (urbn_management_scaler, columns = ['sentiment_score'])\n",
    "urbn_sales_scaler = pd.DataFrame (urbn_sales_scaler, columns = ['sentiment_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_topic_stock_table = pd.concat([urbn_stock_date, urbn_stock_scaler], axis=1)\n",
    "urbn_topic_management_table = pd.concat([urbn_management_date, urbn_management_scaler], axis=1)\n",
    "urbn_topic_sales_table = pd.concat([urbn_sales_date, urbn_sales_scaler], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic = urbn_topic_stock_table.sort_values(by =\"Date\")\n",
    "urbn_management_topic = urbn_topic_management_table.sort_values(by =\"Date\")\n",
    "urbn_sales_topic = urbn_topic_sales_table.sort_values(by =\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "urbn_stock_topic['Date'] = pd.to_datetime(urbn_stock_topic['Date'])\n",
    "urbn_management_topic['Date'] = pd.to_datetime(urbn_management_topic['Date'])\n",
    "urbn_sales_topic['Date'] = pd.to_datetime(urbn_sales_topic['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_pure_price = pd.DataFrame(urbn_scaler_price, columns = ['Closing_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_price1 = urbn_stock_price.reset_index()\n",
    "urbn_stockprice_date = urbn_stock_price1[\"Date\"]\n",
    "urbn_stockprice_date = pd.DataFrame({ 'Stock_price_date':urbn_stockprice_date.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_table =pd.concat([urbn_stockprice_date,urbn_pure_price], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_table1 = urbn_stock_table.set_index('Stock_price_date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic2 = urbn_stock_topic.sort_values(by =\"Date\")\n",
    "urbn_management_topic2 = urbn_management_topic.sort_values(by =\"Date\")\n",
    "urbn_sales_topic2 = urbn_sales_topic.sort_values(by =\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic3 = urbn_stock_topic2.set_index(\"Date\")\n",
    "urbn_management_topic3 = urbn_management_topic2.set_index(\"Date\")\n",
    "urbn_sales_topic3 = urbn_sales_topic2.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28268\\3823624490.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28268\\3823624490.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_28268\\3823624490.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)\n"
     ]
    }
   ],
   "source": [
    "urbn_stock_topic_final = urbn_stock_topic3.assign(key=urbn_stock_topic3.index.normalize())\\\n",
    "   .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)\n",
    "urbn_management_topic_final = urbn_management_topic3.assign(key=urbn_management_topic3.index.normalize())\\\n",
    "   .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)\n",
    "urbn_sales_topic_final = urbn_sales_topic3.assign(key=urbn_sales_topic3.index.normalize())\\\n",
    "   .merge(urbn_stock_table1, left_on='key', right_index=True, how='left').drop('key', 1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>Closing_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-09-26 10:15:00</th>\n",
       "      <td>0.845859</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-02 10:37:00</th>\n",
       "      <td>0.499846</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-10-21 10:47:00</th>\n",
       "      <td>0.736661</td>\n",
       "      <td>0.014884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-06 09:43:00</th>\n",
       "      <td>0.305183</td>\n",
       "      <td>0.116700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-05-28 09:49:00</th>\n",
       "      <td>0.499573</td>\n",
       "      <td>0.149201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-02 10:46:00</th>\n",
       "      <td>0.743531</td>\n",
       "      <td>0.505984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-03 05:08:00</th>\n",
       "      <td>0.518318</td>\n",
       "      <td>0.473908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31 11:30:00</th>\n",
       "      <td>0.801090</td>\n",
       "      <td>0.425794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01 02:29:00</th>\n",
       "      <td>0.810007</td>\n",
       "      <td>0.416074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-12 10:43:00</th>\n",
       "      <td>0.801449</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sentiment_score  Closing_price\n",
       "Date                                               \n",
       "2003-09-26 10:15:00         0.845859            NaN\n",
       "2003-10-02 10:37:00         0.499846            NaN\n",
       "2003-10-21 10:47:00         0.736661       0.014884\n",
       "2004-04-06 09:43:00         0.305183       0.116700\n",
       "2004-05-28 09:49:00         0.499573       0.149201\n",
       "...                              ...            ...\n",
       "2022-03-02 10:46:00         0.743531       0.505984\n",
       "2022-03-03 05:08:00         0.518318       0.473908\n",
       "2022-03-31 11:30:00         0.801090       0.425794\n",
       "2022-04-01 02:29:00         0.810007       0.416074\n",
       "2022-04-12 10:43:00         0.801449            NaN\n",
       "\n",
       "[590 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urbn_stock_topic_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm = urbn_stock_topic_final.dropna()\n",
    "urbn_managment_topic_lstm = urbn_management_topic_final.dropna()\n",
    "urbn_sales_topic_lstm = urbn_sales_topic_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm = urbn_stock_topic_final.fillna(method = 'ffill')\n",
    "urbn_managment_topic_lstm = urbn_management_topic_final.fillna(method = 'ffill')\n",
    "urbn_sales_topic_lstm = urbn_sales_topic_final.fillna(method= 'ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm = urbn_stock_topic_final.fillna(method = 'bfill')\n",
    "urbn_managment_topic_lstm = urbn_management_topic_final.fillna(method = 'bfill')\n",
    "urbn_sales_topic_lstm = urbn_sales_topic_final.fillna(method= 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm.to_csv('urbn_stock_topic_lstm_bert.csv', index = True)\n",
    "urbn_managment_topic_lstm.to_csv('urbn_management_topic_lstm_bert.csv', index = True)\n",
    "urbn_sales_topic_lstm.to_csv('urbn_sales_topic_lstm_bert.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment_score    False\n",
       "Closing_price       True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urbn_stock_topic_lstm.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm = urbn_stock_topic_final.fillna(method = 'ffill')\n",
    "urbn_sales_topic_lstm = urbn_sales_topic_final.fillna(method= 'ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "urbn_stock_topic_lstm.to_csv('urbn_stock_topic_lstm_ffill_bert.csv', index = True)\n",
    "urbn_managment_topic_lstm.to_csv('urbn_management_topic_lstm_ffill_bert.csv', index = True)\n",
    "urbn_sales_topic_lstm.to_csv('urbn_sales_topic_lstm_ffill_bert.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

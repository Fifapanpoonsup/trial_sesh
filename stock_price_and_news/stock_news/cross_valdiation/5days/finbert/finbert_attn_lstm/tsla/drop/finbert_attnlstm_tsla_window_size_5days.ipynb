{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.nn import Module,Sequential,ReLU, LSTM , Linear, Tanh\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from torch.nn import MSELoss,L1Loss\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from math import sqrt\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOOKBACK = 5\n",
    "HORIZON = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6826, 3)\n"
     ]
    }
   ],
   "source": [
    "gps_stock = pd.read_csv(r\"C:\\Users\\User\\Desktop\\thesis_final\\stock_price_and_news\\stock_news\\news_dataset\\final_dataset\\tsla_lstm_new.csv\")\n",
    "print(gps_stock.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6826, 2)\n"
     ]
    }
   ],
   "source": [
    "gps_stock.drop(columns=['Date'], inplace = True)\n",
    "gps_stock = gps_stock.values\n",
    "print(gps_stock.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockingTimeSeriesSplit():\n",
    "    def __init__(self, n_splits):\n",
    "        self.n_splits = n_splits\n",
    "    \n",
    "    def get_n_splits(self, X, y, groups):\n",
    "        return self.n_splits\n",
    "    \n",
    "    def split(self, X, y=None, groups=None):\n",
    "        n_samples = len(X)\n",
    "        k_fold_size = n_samples // self.n_splits\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        margin = 0\n",
    "        for i in range(self.n_splits):\n",
    "            start = i * k_fold_size\n",
    "            stop = start + k_fold_size\n",
    "            mid = int(0.9 * (stop - start)) + start\n",
    "            yield indices[start: mid], indices[mid + margin: stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(lookback,horizon, price):\n",
    "\n",
    "    # (3000,2)\n",
    "\n",
    "    data_initial = price\n",
    "    window_size = lookback + horizon\n",
    "    data = []\n",
    "    for index in range(len(data_initial) - window_size):\n",
    "        data.append(data_initial[index:index+ window_size])\n",
    "    data = np.array(data) \n",
    "    # print(data.shape)\n",
    "    # (300,6,2)\n",
    "\n",
    "    # test_size = int(np.round(0.2*data.shape[0]))\n",
    "    # train_set_size = data.shape[0] - (test_size)\n",
    "    train_set = data\n",
    "    \n",
    "    x_train = train_set[:,:lookback,:]\n",
    "    # print(x_train.shape)\n",
    "    \n",
    "\n",
    "    y_train = train_set[:,lookback:lookback + horizon, 1]\n",
    "    y_train = y_train.reshape(-1,horizon)\n",
    "    # print(y_train.shape)\n",
    "\n",
    "    # test_set = data[train_set_size:]\n",
    "    # x_test = test_set[:,:lookback]\n",
    "    # y_test = test_set[:,lookback:lookback+ horizon]\n",
    "    # y_test = y_test.reshape(-1,horizon)\n",
    "    \n",
    "    #x_train = x_train.reshape(x_train.shape[0],x_train.shape[2],x_train.shape[1])\n",
    "    #y_train = y_train.reshape(y_train.shape[0],y_train.shape[2],y_train.shape[1])\n",
    "    # x_test = x_test.reshape(x_test.shape[0],x_test.shape[2],x_test.shape[1])\n",
    "    #y_test = y_test.reshape(y_test.shape[0],y_test.shape[2],y_test.shape[1])\n",
    "\n",
    "\n",
    "    return [x_train, y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,X,y):\n",
    "        self.X = X\n",
    "        self.y = y \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "\n",
    "class BiLSTM_self_attention(nn.Module):\n",
    "    '''\n",
    "    Expected Input Shape: (batch, seq_len, channels)\n",
    "    '''\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, bidirectional, dropout=0):\n",
    "        super(BiLSTM_self_attention, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        if bidirectional :\n",
    "            self.n_direction = 2\n",
    "            \n",
    "        self.lstm       = nn.LSTM(input_dim, \n",
    "                                  hidden_dim, \n",
    "                                  num_layers, \n",
    "                                  bidirectional=bidirectional, \n",
    "                                  dropout=dropout, \n",
    "                                  batch_first=True\n",
    "                                 )\n",
    "        self.fc      = nn.Linear( hidden_dim  * self.n_direction , output_dim)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.lin_Q = nn.Linear(self.hidden_dim * self.n_direction, self.hidden_dim * self.n_direction)\n",
    "        self.lin_K = nn.Linear(self.hidden_dim * self.n_direction, self.hidden_dim * self.n_direction)\n",
    "        self.lin_V = nn.Linear(self.hidden_dim * self.n_direction, self.hidden_dim * self.n_direction)\n",
    "\n",
    "    def self_attention_net(self, lstm_output ):\n",
    "        q = self.lin_Q(torch.clone(lstm_output))\n",
    "        k = self.lin_K(torch.clone(lstm_output))\n",
    "        v = self.lin_V(torch.clone(lstm_output))\n",
    "        \n",
    "        attn_w = torch.bmm(q, k.transpose(1, 2))\n",
    "        sfmx_attn_w = self.softmax(attn_w)\n",
    "        context = torch.bmm(sfmx_attn_w, v)\n",
    "\n",
    "        return torch.mean(context, dim=1)\n",
    "  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        h0 = torch.zeros(self.num_layers * self.n_direction , x.size(0), self.hidden_dim).to(device).float()\n",
    "        c0 = torch.zeros(self.num_layers * self.n_direction , x.size(0), self.hidden_dim).to(device).float()\n",
    "       \n",
    "        # Forward propagate LSTM\n",
    "        out, (_, _) = self.lstm(x, (h0, c0)) # out.shape : tensor of shape (batch_size, seq_length, hidden_size)\n",
    "\n",
    "        context = self.self_attention_net(out)\n",
    "    \n",
    "        return self.fc( context  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "valid_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(data_loader, model,optimizer, criterion,) :\n",
    "    running_loss = 0\n",
    "    \n",
    "    for (X,y) in (data_loader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "       \n",
    "        #l2_lambda = 0.001\n",
    "        #l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "        #loss = loss + l2_lambda *l2_norm\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(X.float())\n",
    "        loss = criterion(preds, y.float())\n",
    "       \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += np.sqrt(loss.item())\n",
    "\n",
    "    train_loss = running_loss/len(data_loader)\n",
    "    # print(f'train_loss{train_loss}')\n",
    "\n",
    "    return train_loss, model\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def Valid(data_loader,  model, optimizer, criterion):\n",
    "    \"\"\"\n",
    "    return y_true, y_hat\n",
    "    \"\"\"\n",
    "    running_loss = 0\n",
    "    \n",
    "    \n",
    "    y_hat = []\n",
    "    y_true = []\n",
    "    with torch.no_grad():\n",
    "        for (X, y) in (data_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "         \n",
    "            y_true = [*y_true,*(y.reshape(-1).tolist()) ]\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X.float())\n",
    "         \n",
    "            y_hat = [*y_hat, *(preds.reshape(-1).tolist())]\n",
    "      \n",
    "            loss = criterion(preds,y.float())\n",
    "            running_loss += np.sqrt(loss.item())\n",
    "            \n",
    "        valid_loss = running_loss/len(data_loader)\n",
    "        \n",
    "        # print(f'valid_loss {valid_loss}')\n",
    "\n",
    "    return y_true, y_hat, valid_loss, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  5\n",
      "Best model :  9\n",
      "Best model :  12\n",
      "Best model :  17\n",
      "Best model :  18\n",
      "Best model :  19\n",
      "Best model :  120\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.004924079918478351\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  5\n",
      "Best model :  6\n",
      "Best model :  10\n",
      "Best model :  14\n",
      "Best model :  18\n",
      "Best model :  22\n",
      "Best model :  25\n",
      "Best model :  26\n",
      "Best model :  27\n",
      "Best model :  28\n",
      "Best model :  29\n",
      "Best model :  30\n",
      "Best model :  31\n",
      "Best model :  32\n",
      "Best model :  33\n",
      "Best model :  34\n",
      "Best model :  35\n",
      "Best model :  37\n",
      "Best model :  38\n",
      "Best model :  39\n",
      "Best model :  40\n",
      "Best model :  41\n",
      "Best model :  42\n",
      "Best model :  43\n",
      "Best model :  44\n",
      "Best model :  45\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  48\n",
      "Best model :  49\n",
      "Best model :  50\n",
      "Best model :  51\n",
      "Best model :  52\n",
      "Best model :  53\n",
      "Best model :  54\n",
      "Best model :  55\n",
      "Best model :  56\n",
      "Best model :  57\n",
      "Best model :  58\n",
      "Best model :  59\n",
      "Best model :  60\n",
      "Best model :  61\n",
      "Best model :  62\n",
      "Best model :  63\n",
      "Best model :  64\n",
      "Best model :  65\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  100\n",
      "Best model :  101\n",
      "Best model :  102\n",
      "Best model :  103\n",
      "Best model :  104\n",
      "Best model :  105\n",
      "Best model :  106\n",
      "Best model :  107\n",
      "Best model :  108\n",
      "Best model :  109\n",
      "Best model :  110\n",
      "Best model :  111\n",
      "Best model :  112\n",
      "Best model :  113\n",
      "Best model :  114\n",
      "Best model :  115\n",
      "Best model :  116\n",
      "Best model :  117\n",
      "Best model :  118\n",
      "Best model :  119\n",
      "Best model :  120\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "0.01069644310330172\n",
      "Best model :  0\n",
      "Best model :  3\n",
      "Best model :  4\n",
      "Best model :  11\n",
      "Best model :  14\n",
      "Best model :  17\n",
      "Best model :  20\n",
      "Best model :  23\n",
      "Best model :  26\n",
      "Best model :  27\n",
      "Best model :  28\n",
      "Best model :  32\n",
      "Best model :  33\n",
      "Best model :  37\n",
      "Best model :  38\n",
      "Best model :  42\n",
      "Best model :  43\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.002700229929588723\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  4\n",
      "Best model :  5\n",
      "Best model :  8\n",
      "Best model :  9\n",
      "Best model :  12\n",
      "Best model :  16\n",
      "Best model :  19\n",
      "Best model :  22\n",
      "Best model :  26\n",
      "Best model :  27\n",
      "Best model :  28\n",
      "Best model :  31\n",
      "Best model :  32\n",
      "Best model :  33\n",
      "Best model :  36\n",
      "Best model :  37\n",
      "Best model :  38\n",
      "Best model :  39\n",
      "Best model :  40\n",
      "Best model :  41\n",
      "Best model :  42\n",
      "Best model :  43\n",
      "Best model :  44\n",
      "Best model :  45\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  48\n",
      "Best model :  49\n",
      "Best model :  50\n",
      "Best model :  51\n",
      "Best model :  52\n",
      "Best model :  53\n",
      "Best model :  54\n",
      "Best model :  55\n",
      "Best model :  56\n",
      "Best model :  57\n",
      "Best model :  58\n",
      "Best model :  59\n",
      "Best model :  60\n",
      "Best model :  61\n",
      "Best model :  62\n",
      "Best model :  63\n",
      "Best model :  64\n",
      "Best model :  65\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  77\n",
      "Best model :  78\n",
      "Best model :  79\n",
      "Best model :  80\n",
      "Best model :  81\n",
      "Best model :  82\n",
      "Best model :  83\n",
      "Best model :  84\n",
      "Best model :  85\n",
      "Best model :  86\n",
      "Best model :  87\n",
      "Best model :  88\n",
      "Best model :  89\n",
      "Best model :  90\n",
      "Best model :  91\n",
      "Best model :  92\n",
      "Best model :  93\n",
      "Best model :  94\n",
      "Best model :  95\n",
      "Best model :  96\n",
      "Best model :  97\n",
      "Best model :  98\n",
      "Best model :  99\n",
      "Best model :  100\n",
      "Best model :  101\n",
      "Best model :  102\n",
      "Best model :  103\n",
      "Best model :  104\n",
      "Best model :  105\n",
      "Best model :  106\n",
      "Best model :  107\n",
      "Best model :  108\n",
      "Best model :  109\n",
      "Best model :  110\n",
      "Best model :  111\n",
      "Best model :  112\n",
      "Best model :  113\n",
      "Best model :  114\n",
      "Best model :  115\n",
      "Best model :  116\n",
      "Best model :  117\n",
      "Best model :  118\n",
      "Best model :  119\n",
      "Best model :  120\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.0019931901584677417\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  3\n",
      "Best model :  4\n",
      "Best model :  7\n",
      "Best model :  11\n",
      "Best model :  14\n",
      "Best model :  18\n",
      "Best model :  23\n",
      "Best model :  24\n",
      "Best model :  25\n",
      "Best model :  26\n",
      "Best model :  28\n",
      "Best model :  29\n",
      "Best model :  30\n",
      "Best model :  31\n",
      "Best model :  32\n",
      "Best model :  33\n",
      "Best model :  34\n",
      "Best model :  35\n",
      "Best model :  36\n",
      "Best model :  37\n",
      "Best model :  38\n",
      "Best model :  39\n",
      "Best model :  40\n",
      "Best model :  41\n",
      "Best model :  42\n",
      "Best model :  43\n",
      "Best model :  44\n",
      "Best model :  45\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  48\n",
      "Best model :  49\n",
      "Best model :  50\n",
      "Best model :  51\n",
      "Best model :  52\n",
      "Best model :  53\n",
      "Best model :  54\n",
      "Best model :  55\n",
      "Best model :  56\n",
      "Best model :  57\n",
      "Best model :  58\n",
      "Best model :  59\n",
      "Best model :  60\n",
      "Best model :  61\n",
      "Best model :  62\n",
      "Best model :  63\n",
      "Best model :  64\n",
      "Best model :  65\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  77\n",
      "Best model :  78\n",
      "Best model :  79\n",
      "Best model :  80\n",
      "Best model :  81\n",
      "Best model :  82\n",
      "Best model :  83\n",
      "Best model :  84\n",
      "Best model :  85\n",
      "Best model :  86\n",
      "Best model :  87\n",
      "Best model :  88\n",
      "Best model :  89\n",
      "Best model :  90\n",
      "Best model :  91\n",
      "Best model :  92\n",
      "Best model :  93\n",
      "Best model :  94\n",
      "Best model :  95\n",
      "Best model :  96\n",
      "Best model :  97\n",
      "Best model :  98\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.005141533932859194\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  2\n",
      "Best model :  38\n",
      "Best model :  39\n",
      "Best model :  40\n",
      "Best model :  41\n",
      "Best model :  42\n",
      "Best model :  43\n",
      "Best model :  44\n",
      "Best model :  45\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  48\n",
      "Best model :  49\n",
      "Best model :  50\n",
      "Best model :  51\n",
      "Best model :  52\n",
      "Best model :  53\n",
      "Best model :  54\n",
      "Best model :  55\n",
      "Best model :  56\n",
      "Best model :  57\n",
      "Best model :  58\n",
      "Best model :  59\n",
      "Best model :  60\n",
      "Best model :  61\n",
      "Best model :  62\n",
      "Best model :  63\n",
      "Best model :  64\n",
      "Best model :  65\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  77\n",
      "Best model :  78\n",
      "Best model :  79\n",
      "Best model :  80\n",
      "Best model :  81\n",
      "Best model :  82\n",
      "Best model :  83\n",
      "Best model :  84\n",
      "0.016532603086509955\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  2\n",
      "Best model :  3\n",
      "Best model :  46\n",
      "Best model :  47\n",
      "Best model :  48\n",
      "Best model :  49\n",
      "Best model :  50\n",
      "Best model :  51\n",
      "Best model :  52\n",
      "Best model :  53\n",
      "Best model :  54\n",
      "Best model :  55\n",
      "Best model :  56\n",
      "Best model :  57\n",
      "Best model :  58\n",
      "Best model :  59\n",
      "Best model :  60\n",
      "Best model :  61\n",
      "Best model :  62\n",
      "Best model :  63\n",
      "Best model :  64\n",
      "Best model :  65\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  77\n",
      "Best model :  78\n",
      "Best model :  79\n",
      "Best model :  80\n",
      "Best model :  81\n",
      "Best model :  82\n",
      "Best model :  83\n",
      "Best model :  84\n",
      "Best model :  85\n",
      "Best model :  86\n",
      "Best model :  87\n",
      "Best model :  88\n",
      "Best model :  89\n",
      "Best model :  90\n",
      "Best model :  91\n",
      "Best model :  92\n",
      "Best model :  93\n",
      "Best model :  94\n",
      "Best model :  95\n",
      "Best model :  96\n",
      "Best model :  97\n",
      "Best model :  98\n",
      "Best model :  99\n",
      "Best model :  100\n",
      "Best model :  101\n",
      "Best model :  102\n",
      "Best model :  103\n",
      "Best model :  104\n",
      "Best model :  105\n",
      "Best model :  106\n",
      "Best model :  107\n",
      "Best model :  108\n",
      "Best model :  109\n",
      "Best model :  110\n",
      "Best model :  111\n",
      "Best model :  112\n",
      "Best model :  113\n",
      "Best model :  114\n",
      "Best model :  115\n",
      "Best model :  116\n",
      "Best model :  117\n",
      "Best model :  118\n",
      "Best model :  119\n",
      "Best model :  120\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.027982709646858683\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  2\n",
      "Best model :  7\n",
      "Best model :  8\n",
      "Best model :  11\n",
      "Best model :  66\n",
      "Best model :  67\n",
      "Best model :  68\n",
      "Best model :  69\n",
      "Best model :  70\n",
      "Best model :  71\n",
      "Best model :  72\n",
      "Best model :  73\n",
      "Best model :  74\n",
      "Best model :  75\n",
      "Best model :  76\n",
      "Best model :  77\n",
      "Best model :  78\n",
      "Best model :  79\n",
      "Best model :  80\n",
      "Best model :  81\n",
      "Best model :  82\n",
      "Best model :  83\n",
      "Best model :  84\n",
      "Best model :  85\n",
      "0.027819601428824982\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  2\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.04293291401951922\n",
      "Best model :  0\n",
      "Best model :  1\n",
      "Best model :  2\n",
      "Best model :  3\n",
      "Best model :  8\n",
      "Best model :  9\n",
      "Best model :  10\n",
      "Best model :  119\n",
      "Best model :  120\n",
      "Best model :  121\n",
      "Best model :  122\n",
      "Best model :  123\n",
      "Best model :  124\n",
      "Best model :  125\n",
      "Best model :  126\n",
      "Best model :  127\n",
      "Best model :  128\n",
      "Best model :  129\n",
      "Best model :  130\n",
      "Best model :  131\n",
      "Best model :  132\n",
      "Best model :  133\n",
      "Best model :  134\n",
      "Best model :  135\n",
      "Best model :  136\n",
      "Best model :  137\n",
      "Best model :  138\n",
      "Best model :  139\n",
      "Best model :  140\n",
      "Best model :  141\n",
      "Best model :  142\n",
      "Best model :  143\n",
      "Best model :  144\n",
      "Best model :  145\n",
      "Best model :  146\n",
      "Best model :  147\n",
      "Best model :  148\n",
      "Best model :  149\n",
      "Best model :  150\n",
      "Best model :  151\n",
      "Best model :  152\n",
      "Best model :  153\n",
      "Best model :  154\n",
      "Best model :  155\n",
      "Best model :  156\n",
      "Best model :  157\n",
      "Best model :  158\n",
      "Best model :  159\n",
      "Best model :  160\n",
      "Best model :  161\n",
      "Best model :  162\n",
      "Best model :  163\n",
      "Best model :  164\n",
      "Best model :  165\n",
      "Best model :  166\n",
      "Best model :  167\n",
      "Best model :  168\n",
      "Best model :  169\n",
      "Best model :  170\n",
      "Best model :  171\n",
      "Best model :  172\n",
      "Best model :  173\n",
      "Best model :  174\n",
      "Best model :  175\n",
      "Best model :  176\n",
      "Best model :  177\n",
      "Best model :  178\n",
      "Best model :  179\n",
      "Best model :  180\n",
      "Best model :  181\n",
      "Best model :  182\n",
      "Best model :  183\n",
      "Best model :  184\n",
      "Best model :  185\n",
      "Best model :  186\n",
      "Best model :  187\n",
      "Best model :  188\n",
      "Best model :  189\n",
      "Best model :  190\n",
      "Best model :  191\n",
      "Best model :  192\n",
      "Best model :  193\n",
      "Best model :  194\n",
      "Best model :  195\n",
      "Best model :  196\n",
      "Best model :  197\n",
      "Best model :  198\n",
      "Best model :  199\n",
      "0.028181671872109428\n",
      "[0.004924079918478351, 0.01069644310330172, 0.002700229929588723, 0.0019931901584677417, 0.005141533932859194, 0.016532603086509955, 0.027982709646858683, 0.027819601428824982, 0.04293291401951922, 0.028181671872109428]\n",
      "0.0168904977096518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spliter = BlockingTimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "cv_test_losses = []\n",
    "cv_train_losses = []\n",
    "cv_val_losses = []\n",
    "\n",
    "for trainval_idx ,test_idx in spliter.split(gps_stock):\n",
    "    # print(trainval_idx)\n",
    "    # print(test_idx)\n",
    "\n",
    "    train_idx = trainval_idx[ : int(len(trainval_idx)*0.8)]\n",
    "    val_idx   = trainval_idx[int(len(trainval_idx)*0.8) : ]\n",
    "\n",
    "    x_train_unsplit = gps_stock[train_idx,:]\n",
    "    x_val_unsplit  = gps_stock[val_idx,:]\n",
    "    x_test_unsplit = gps_stock[test_idx,:]\n",
    "\n",
    "    # print(x_train_unsplit.shape)\n",
    "    # adadasdas\n",
    "    # print(train_idx)\n",
    "    # print(val_idx)\n",
    "\n",
    "    x_train_gps, y_train_gps = split_data(LOOKBACK, HORIZON, x_train_unsplit)\n",
    "    x_val_gps, y_val_gps = split_data(LOOKBACK, HORIZON, x_val_unsplit)\n",
    "    x_test_gps, y_test_gps = split_data(LOOKBACK, HORIZON, x_test_unsplit)\n",
    "\n",
    "    # print(x_train_gps.shape)\n",
    "    # print(y_train_gps.shape)\n",
    "\n",
    "    # print(x_val_gps.shape)\n",
    "    # print(y_val_gps.shape)\n",
    "\n",
    "    # print(x_test_gps.shape)\n",
    "    # print(y_test_gps.shape)\n",
    "\n",
    "\n",
    "    train_dataset_gps = cnn_dataset(x_train_gps,y_train_gps)\n",
    "    train_loader_gps = torch.utils.data.DataLoader(train_dataset_gps, batch_size =128 , shuffle = False)\n",
    "    test_dataset_gps = cnn_dataset(x_test_gps,y_test_gps)\n",
    "    test_loader_gps = torch.utils.data.DataLoader(test_dataset_gps,batch_size=128,shuffle=False)\n",
    "    valid_dataset_gps = cnn_dataset(x_val_gps,y_val_gps)\n",
    "    valid_loader_gps = torch.utils.data.DataLoader(valid_dataset_gps,batch_size=128,shuffle=False)\n",
    "    # print(len(train_dataset_gps))\n",
    "    \n",
    "    model = BiLSTM_self_attention(input_dim= 2, hidden_dim= 64 , num_layers= 2 , output_dim= HORIZON, bidirectional = True)\n",
    "    model = model.to(device)\n",
    "    criterion = MSELoss(reduction= 'mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4, weight_decay= 1e-15)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    epochs = 200\n",
    "\n",
    "    best_val_loss = 1e+9\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # print(epoch)\n",
    "        # print('epochs {}/{}'.format(epoch+1,epochs))\n",
    "        train_loss , model               = Train(train_loader_gps, model, optimizer, criterion)\n",
    "        y_true, y_hat, valid_loss , model = Valid(valid_loader_gps, model, optimizer, criterion)\n",
    "\n",
    "        # print(train_loss)\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(valid_loss)\n",
    "\n",
    "        curr_val_loss = valid_loss\n",
    "\n",
    "        if curr_val_loss < best_val_loss:\n",
    "            best_model = copy.deepcopy(model)\n",
    "            best_val_loss = curr_val_loss\n",
    "            print(\"Best model : \", epoch)\n",
    "\n",
    "    \n",
    "    y_test_true, y_test_hat, test_loss , _ = Valid(test_loader_gps, best_model, optimizer, criterion)\n",
    "\n",
    "    print(test_loss)\n",
    "    cv_test_losses.append(test_loss)\n",
    "    cv_train_losses.append(train_losses)\n",
    "    cv_val_losses.append(val_losses)\n",
    "    # break\n",
    "\n",
    "print(cv_test_losses)\n",
    "print(sum(cv_test_losses) / len(cv_test_losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
